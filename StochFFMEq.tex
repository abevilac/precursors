\documentclass{article}
\usepackage{amsmath,amssymb,amstext,mathtools,array,url,bm,graphicx,color,epsfig}
\usepackage{fullpage,setspace}
\usepackage{authblk}
\usepackage{filecontents}
\usepackage{natbib}
\usepackage{lineno}
%\usepackage[colorlinks]{hyperref}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{float}
\usepackage[flushleft]{threeparttable}

\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\begin{document}
\title{\bf A doubly stochastic enhancement of the Failure Forecast Method using a noisy mean-reverting process}
\author[1]{Andrea Bevilacqua}
\author[2]{E. Bruce Pitman}
\author[3,4]{Abani K. Patra}
\author[5]{Augusto Neri}

\affil[1]{\textit{Dept. of Geology, University at Buffalo, Buffalo, NY} }
\affil[2]{\textit{Dept. of Materials Design and Innovation, University at Buffalo, NY}}
\affil[3]{\textit{Dept. of Mech. and  Aero. Eng., University at Buffalo, Buffalo, NY} }
\affil[4]{\textit{Comp. Data Science and Eng., University at Buffalo, Buffalo, NY}}
\affil[5]{\textit{Sezione di Pisa, Istituto Nazionale di Geofisica e Vulcanologia, Pisa, Italy}}

\date{\texttt{\{abevilac,pitman,abani\}@buffalo.edu; augusto.neri@ingv.it}}


\maketitle
\abstract
We introduce a doubly stochastic method for performing material failure theory based forecasts of volcanic eruptions. The method enhances the well known Failure Forecast Method equation, introducing a new formulation similar to the Hull-White model. In particular, we incorporate a stochastic noise term in the original equation, and we extend the uncertainty quantification beyond previous efforts. The model is a stochastic differential equation (SDE) with a mean reverting solution, which assumes the traditional ordinary differential equatoin (ODE) as the mean solution. Our implementation allows the model to make excursions from the classical solutions, by including uncertainty in the estimation. The doubly stochastic formulation is particularly powerful, in that it provides a complete posterior probability distribution, allowing civil protection officials to determine a worst case scenario with a specified level of confidence. We validate the new method on historical datasets of precursory signals, across a wide range of possible values of convexity in the solutions and amounts of scattering in the observations. The results show the increased forecasting skill of the doubly stochastic formulation of the SDE.

\tableofcontents

\section{Introduction}
The Failure Forecast Method (FFM) for volcanic eruptions is a classical tool in the interpretation of monitoring data as potential precursors, providing quantitative predictions of the eruption onset. The basis of FFM is a fundamental law for failing materials:
$$dX/dt=AX^\alpha,$$
where $X$ is the rate of the precursor signal, and $\alpha$, $A$ are model parameters. The solution $X$ is a power law of exponent $1/(1-\alpha)$ diverging at time $t_f$, called failure time. The model represents the potential cascading of precursory signals leading to the final rupture of materials, with $t_f$ a good approximation to the eruption onset time $t_e$.

The FFM equation was originally developed in landslide forecasting \citep{Voight1987, Voight1988b, Voight1989b}, and later applied in eruption forecasting \citep{Voight1988, Voight1989, Cornelius1995}. The method was retrospectively applied to several volcanic systems, including dome growth episodes and explosive volcanic eruptions \citep{Voight1991, Cornelius1994, Cornelius1996, Voight2000}. Volcanic tremor characteristics were studied with the FFM method and related to the seismic signals of the multi-scale rock cracking \citep{Kilburn1998,Ortiz2003,Kilburn2003}. Experimental and field studies of the physics behind the rate-increase of volcano-tectonic earthquakes are available \citep{Smith2009,Smith2010}. Generalized (power law) regression appeared to improve the accuracy of the forecasts \citep{Bell2011}. However, sometimes the method fails to predict the time of the eruption, and some volcanic systems are often characterized by prolonged unrest and ambiguous signals \citep{Chiodini2016}. A full probability assessment, including uncertainty quantification (UQ), is required, and it is the purpose of our investigations.

In this study, we generalize the classical FFM approach by incorporating a stochastic noise in the original  ordinary differential equation (ODE) converting it into a stochastic differential equation (SDE), and systematically characterize the uncertainty. Embedding noise in the model can enable the FFM equation to have greater forecasting skill by focusing on averages and moments. Sudden changes in the power law properties are indeed possible. In our model, the prediction is thus perturbed inside a range that can be tuned, producing probabilistic forecasts. 

In more detail, in the original equation the change of variables $\eta=X^{1-\alpha}$ implies:
$$d\eta/dt=(1-\alpha)A,$$
i.e. a straight line which hits zero at $t_f$. The most efficient graphical and computational methods indeed rely on the regression analysis of inverse rate plots. We re-define $\eta$ with:
$$d\eta_t=\gamma[(1-\alpha)A(t-t_0)+\eta_{t_0}-\eta_t]dt+\sigma dWt,$$
also called Hull-White model in financial mathematics \citep{HullWhite1990}. The parameter $\sigma$ defines the strength of the noise, and $\gamma$ the rapidity of the mean-reversion property. We validate the new method on historical datasets of precursory signals already studied with the classical FFM, including tilt, line-length, and fault movement at Mt. St. Helens, 1981-82, seismic signals registered from Bezymyanny, 1960, and surface movement of Mt. Toc, 1960-63 \citep{Voight1988}.

A fundamental aspect of our formulation is the possibility of a doubly stochastic UQ. Doubly stochastic models describe the effect of uncertainty in the formulation of aleatory processes, and have been successfully applied in volcanology \citep{Sparks2004, Marzocchi2012, Bevilacqua2016}. Thus, doubly stochastic probability density functions (pdf) and estimates are themselves affected by uncertainty. This approach has been applied in spatial problems concerning eruptive vent/fissure mapping \citep{Selva2012, Bevilacqua2015, Tadini2017a, Tadini2017b, Bevilacqua2017a}, long-term temporal problems based on past eruption record \citep{Bebbington2013, Bevilacqua2016b, Richardson2017, Bevilacqua2018}, and hazard assessments \citep{Neri2015, Bevilacqua2017b}. In this study, a doubly stochastic model is applied in a short-term eruption forecasting method based on precursory signals.

\newpage
\section{The Failure Forecast Method ODE}
The classical Failure Forecast Method (FFM) equation is:
\begin{align}\label{eq1}
\dot\Omega^{-\alpha}\ddot{\Omega}=A,
\end{align}
where $\alpha\ge 1$, $A>0$, and $\Omega:[0,T]\rightarrow \mathbb R$ a precursor function, like ground or fault displacement, tilt, seismic strain release \citep{Voight1988}. For simplicity we call $X:=\dot\Omega$, and the equation \ref{eq1} reads:
$$X^{-\alpha}\frac{dX}{dt}=A.$$

If $\alpha=1$, the solution is the exponential $X(t)=X(t_0)\exp[A(t-t_0)]$. However, most common observations in volcanology give $\alpha\in[1.7,2.3]$. We note that if $\alpha<1$ a solution exists in $[0,+\infty]$ and does not diverge in a finite time \citep{Cornelius1995}.

If $\alpha > 1$, we see:
$$\frac{dX}{dt}^{1-\alpha}=(1-\alpha)X^{-\alpha}\frac{dX}{dt},$$
and the FFM equation becomes:
$$\frac{dX^{1-\alpha}}{dt}=(1-\alpha)A.$$
Simplifying again the notation, we can call $\eta=X^{1-\alpha}$, and the FFM reads:
$$\frac{d\eta}{dt}=(1-\alpha)A.$$
We can solve this equation by immediate integration,
\begin{align}\label{eq2a}
\eta(t)=(1-\alpha)A(t-t_0)+\eta(t_0),
\end{align}
and equivalently:
\begin{align}\label{eq2b}
X(t)=\left[(1-\alpha)A(t-t_0)+X(t_0)^{1-\alpha}\right]^{\frac{1}{1-\alpha}}.
\end{align}

The original method required fitting the two parameters $\alpha$ and $A$ on the monitoring data, and then to estimate the time of failure $t_f$, such that $X(t_f) =+\infty$, or equivalently $\eta(t_f)=0$. It follows:
$$\eta(t)=(\alpha-1)A(t_f-t),$$
and so:
$$t_f-t=\frac{\eta(t)}{(\alpha-1)A}.$$
We note that an estimate of $\eta(t)$ is thus necessary to make forecasts, a non-trivial process if noise is present.

The effect of varying parameters $\alpha$ and $A$ on the equation \ref{eq2b} is displayed in Figure \ref{Fig1}a,b. Our purpose is to forecast the failure time $t_f:=\{t:X(t)^{-1}=0\}$ and hence it is more practical to examine the plot of $X^{-1}=\eta^{\frac{1}{\alpha-1}}$, shown in Fig.\ref{Fig1}b. The parameter $\alpha$ defines the convexity of that function - for $\alpha\le2$ it is convex, for $\alpha\ge2$ it is concave. The value $\alpha=2$ produces a straight line. We call it the {\it convexity} parameter.

In equation \ref{eq2a} the parameter $A$ changes the time scale of the equation, and so defines the constant slope of $\eta$, that is $-A$. Hence we call it the {\it slope} parameter.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{Fig1_plus.png}
\caption{(a,b) ODE solution, (a) X, and (b) 1/X. (c-f) SDE solution, (c,e) with $\gamma=0$, (d,f) with $\gamma=1$. (c,d) with $\alpha=2$, (e,f) with $\alpha=1.7$. In all the plots, the colored lines are the ODE solutions, the black lines are 50 random paths of the SDE solutions.}
\label{Fig1}
\end{figure}

\section{The Failure Forecast Method SDE}
We assume that the equation is not exactly verified, but there is a transient difference, which however decreases exponentially through time. The equation becomes:
$$\eta(t)=(1-\alpha)A(t-t_0) +\beta\exp(-\gamma t)+\eta(t_0),$$
where $\beta$ is the value at $t=0$ and $\gamma$ is the rate of decay of this error term.

This allows a reformulation of the equation. Given that:
$$\eta(t)-(1-\alpha)A(t-t_0)-\eta(t_0)=\beta\exp(-\gamma t),$$
then
$$\ln\left[\eta(t)-(1-\alpha)A(t-t_0)-\eta(t_0)\right]=-\gamma t+ln(\beta).$$
We can take the derivative, and obtain:
$$\left[\eta(t)-(1-\alpha)A(t-t_0)-\eta(t_0)\right]^{-1}\left(\frac{d\eta}{dt}(t)-(1-\alpha)A\right)=-\gamma,$$
and so
$$\frac{d\eta}{dt}=\gamma\left[(1-\alpha)A(t-t_0)+\eta(t_0)-\eta(t)\right]+(1-\alpha)A.$$

In addition, we want to allow for an additive noise affecting the new equation, and the final formulation is:
\begin{align}\label{eq3a}
d\eta_t=\left\{\gamma\left[(1-\alpha)A(t-t_0)+\eta_{t_0}-\eta_t\right]+(1-\alpha)A\right\}dt+\sigma dW_t,
\end{align}
or equivalently:
\begin{align}\label{eq3b}
X_t=\left\{X_{t_0}^{1-\alpha}+\int_{t_0}^t\left\{\gamma\left[(1-\alpha)A(s-t_0)+X_{t_0}^{1-\alpha}-X_s^{1-\alpha}\right]+(1-\alpha)A\right\}dt+\int_{t_0}^t\sigma dW_s\right\}^{\frac{1}{1-\alpha}},
\end{align}
for each $t<t_f$. This is also called a Hull-White model in financial mathematics \citep{HullWhite1990}.

The effect of varying parameters $\sigma$ and $\gamma$ on the SDE solution $X$ is displayed in Figure \ref{Fig1}c-f. In equation \ref{eq3a}, $\sigma$ defines the time scale of the additive noise, and so we call it the {\it noise} parameter. We remark that $X$ is nonlinearly affected by this random noise in equation \ref{eq3b}. The SDE defining $\eta$ is elevated to the exponent $\frac{1}{1-\alpha}$, and even a relatively small noise can significantly change the failure time (see Fig.\ref{Fig1}c,e).

Parameter $\gamma$ defines the time scale of the exponential decay of perturbations with respect to the classical ODE solution. It controls the equation, reverting the paths of the solutions towards the mean curve (see Fig.\ref{Fig1}d,f). We call $\gamma$ the {\it mean-reverting} parameter.

Figure \ref{Fig2} displays three different solutions of $X^{-1}$, assuming convexity parameter $\alpha=1.7$, $2$, or $2.3$. The slope parameter is fixed $A=1e-1$. Plots \ref{Fig2}a,c,e show an example of solutions assuming mean-reverting parameter $\gamma=0$, or $\gamma=0.25$. The noise is additive in \ref{Fig2}a, and weakly nonlinear in \ref{Fig2}c,e. Plots \ref{Fig2}b,d,f display pdf of $t_f$ calculated by Monte Carlo simulation (2,000 samples).

\begin{figure}[H]\vskip-0.5cm
\centering
\includegraphics[width=0.85\textwidth]{Fig2_plus.png}
\caption{SDE solutions, 1/X, (a,b) with $\alpha=2$, (c,d) with $\alpha=1.7$, (e,f) with $\alpha=2.3$. In (a,c,e) the colored lines are random paths of the solution, assuming $\gamma=0$ or $\gamma=0.25$. In (b,d,f) the colored lines are the pdfs of $t_f$, assuming $\gamma=0$ or $\gamma=0.25$. The dotted lines are random paths of the solution. In all the plots the black line is the ODE solution.}
\label{Fig2}
\end{figure}

\section{The mean-reverting properties}
Let $\hat\eta$ be the ODE solution with data $\eta(t_0)$ at time $t_0$. If $\sigma>0$ and $\gamma=0$, the law of Brownian Motion and the linearity of the ODE imply that:
$$\eta(t)-\hat\eta(t)\sim \mathcal N\left(0,\sigma^2(t-t_0)\right).$$
If $\gamma>0$ the {\it mean-reverting} term exponentially reduces $\left|\eta(t)-\hat\eta(t)\right|$. If $\sigma=0$ and the equation starts with $\delta(t_0):=|\eta(t_0)-\hat\eta(t_0)|>0$ we have:
$$\delta(t):=\left|\eta(t)-\hat\eta(t)\right|=\exp[-\gamma(t-t_0)].$$
Figure \ref{Fig3}a shows this example, and $3\gamma^{-1}$ provides the time interval required to have $\delta(t)\simeq\delta(t_0)/20$.

If both $\sigma>0$ and $\gamma>0$, the combined effect of the {\it noise} and the {\it mean-reverting} defines the Ornstein-Uhlenbeck process (from equation \ref{eq3a}, with $A=0$ and $\eta_{t_0}=0$):
\begin{align}\label{eq4a}
d\eta_t=-\gamma\eta_t dt+\sigma dW_t,
\end{align}
whose solution is:
\begin{align}\label{eq4b}
\eta_t\sim\mathcal N\left(0,\frac{\sigma^2}{2\gamma}\left[1-\exp(-2\gamma t)\right]\right)\simeq \mathcal N\left(0,\frac{\sigma^2}{2\gamma}\right),
\end{align}
when $\gamma|t_f-t_0|\gg1$. The constant $K:=\frac{\sigma^2}{2\gamma}$ uniquely defines the probability distribution of the solution of this SDE. Different realizations of this process are displayed in in Figure \ref{Fig3}b. If $\sigma^2$ increases and $\gamma$ decreases, then the perturbations are more frequent, but reverted faster. This may have some effect on the estimate of $t_f$, but discrete data cannot provide any information on perturbations occurred at frequency higher than the measurements. In most of our examples we define $\gamma^{-1}=15$ days. That is, any perturbation decays by 63\% within 15 days, and by 95\% within 45 days, which is close to the total length of the time interval considered. Sensitivity analysis on this parameter is performed in Appendix \ref{A-2}.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{Fig3_plus.png}
\caption{(a) SDE solutions with $\alpha=2$, 1/X, with $\sigma=0$, but $\delta(t_0)>0$. Different colors correspond to different values of $\gamma$. (b) Ornstein-Uhlenbeck processes with equal $K=\frac{\sigma^2}{\gamma}$, but different $(\sigma, \gamma)$.}
\label{Fig3}
\end{figure}

\newpage
\section{Parameter fitting and UQ}
The application of our method requires the estimation of five parameters:
\begin{itemize}
  \item {\it curvature} parameter $\alpha$,
  \item {\it slope} parameter $A$,
  \item {\it noise} parameter $\sigma$,
  \item {\it mean-reverting} parameter $\gamma$,
  \item an unperturbed initial value $\hat\eta(t_0)$.
\end{itemize}
In the following all these parameters are assumed to be positive, and $\alpha > 1$. In particular, the case $\alpha=1$ is trivial, and the cases $\alpha <1$ or $A\le0$ imply $t_f=+\infty$. We note that $\hat\eta(t_0)$ cannot be trivially defined equal to the first observation, because of the perturbations.

Several methods have been adopted in the determination of the parameters in the ODE problem \citep{Voight1988, Cornelius1995, Bell2011}. The Log-rate versus Log-acceleration Technique (LLT), and the Hindsight Technique (HT) can both provide estimates of $\alpha$. They are described in Appendix \ref{A-1}. The first technique is generally less accurate because needs an estimate of the time derivative of the observations. The second technique requires that we know $t_e$ and hence can only be used in retrospective analysis (hindcasting problems). In our formulation we use these methods in the estimation of $\alpha$. The ODE represents the mean path of the SDE, and we approximate its curvature from the available observations.

If $\alpha$ is given, a linearized least square method (LLSM) can be applied to fit parameter $A$ and $\hat\eta(t_0))$ on the inverse plot $1/X$. This is the main method classically adopted as a forecasting technique in the ODE problem (see Appendix \ref{A-1}). We fit the stochastic parameters $\sigma$ and $\gamma$ from the residuals of this linearized problem. In particular, we impose the constant $K=\frac{\sigma^2}{2\gamma}$ to be equal to the variance of the residuals. In summary, we plug-in $\alpha$ from classical LLT or HT in the LLSM, and then we obtain $\left(A,\hat\eta(t_0),K\right)$ as required to the SDE definition.

We apply three different forecast methods on the datasets in \cite{Voight1988}, and we test $t_f$ as an estimator of $t_e$. In all our methods $t_f$ is assumed as a random variable, and its pdf
$$g_{t_f}:\mathbb R\rightarrow \mathbb R+,\quad \int_0^\infty g_{t_f}(x) dx=1$$
is estimated following a classical Gaussian kde method (Silverman Rule).

\begin{itemize}
\item Method 1 is based on the classical ODE, and the corresponding forecasts are displayed in Figure \ref{Fig5}. This is consistent with the original formulation in \cite{Voight1988}. $g_{t_f}$ depends on the statistical uncertainty affecting the pair $(A, \hat\eta(t_0))$ in the regression method. We implement this \emph{model uncertainty} as a bivariate Gaussian in a Monte Carlo of 5,000 samples.

Methods 2 and 3 are both based on the new SDE. 
\item In Method 2, the least-square curve is assumed to be the mean solution, and $g_{t_f}$ is defined by the noise. The forecasts are displayed in Figure \ref{Fig6}. We implement this \emph{aleatory uncertainty} in a Monte Carlo of 5,000 sample paths of the stochastic noise.

\item Method 3 is \emph{doubly stochastic} (e.g. \cite{Bevilacqua2016}). The mean solution is affected first by the statistical uncertainty in the regression method, and then perturbed by the stochastic noise. The values of $g_{t_f}$ are thus reported as 5$^{th}$ percentile, mean, and 95$^{th}$ percentile curves. We remark that the two uncertainties are not independent, because the properties of the noise are related to the residuals in the linearized problem. The forecasts are displayed in Figure \ref{Fig7}. In this case, the mean pdf is based on a Monte Carlo sampling consisting of 10,000 model runs, while the percentile values are based on a hierarchical Monte Carlo of a variable number of samples. This number is tuned according to the different convergence rates observed, but is always above $200\times300=6e5$ samples.
\end{itemize}
\begin{figure}[H]\vskip-0.5cm
\centering
\includegraphics[width=0.85\textwidth]{Fig5_plus.png}
\caption{Estimators of $t_f$ based on Method 1. Blue lines assume $\alpha$ as from LLT, red as from HT. The bold line is $g_{t_f}$. Thin dashed lines bound the $90\%$ confidence interval of the ODE paths, and a thin continuous line is the mean path. A dashed black line marks $t_e$.}
\label{Fig5}
\end{figure}

\begin{figure}[H]\vskip-0.5cm
\centering
\includegraphics[width=0.85\textwidth]{Fig6_plus.png}
\caption{Estimators of $t_f$ based on Method 2. Blue lines assume $\alpha$ as from LLT, red as from HT. A bold line is $g_{t_f}$. Thin dashed lines bound the $90\%$ confidence interval of the SDE paths, and a thin continuous line is the mean path. Thin dotted lines show examples of random paths. A dashed black line marks $t_e$.}
\label{Fig6}
\end{figure}

\begin{figure}[H]\vskip-0.5cm
\centering
\includegraphics[width=0.85\textwidth]{Fig7_plus.png}
\caption{Estimators of $t_f$ based on Method 3. Blue lines assume $\alpha$ as from LLT, red as from HT. A bold line is $g_{t_f}$, and bold dashed lines are its 5$^{th}$ and 95$^{th}$ percentile values. Thin dashed lines bound the $90\%$ confidence interval of the SDE paths, and a thin continuous line is the mean path. Thin dotted lines show examples of random paths. A dashed black line marks $t_e$.}
\label{Fig7}
\end{figure}

The six case studies refer to the volcanic eruptions of Mt. St. Helens (USA), 1982 (a,b) and 1981 (c), and of Bezyamyanny (USSR), 1960 (d), and to the landslides of Mt. Toc (Italy), 1960 (e) and 1963 (f). These datasets are characterized by different values of $\alpha$, and by different confidence intervals in the linear regression. Estimates of $\alpha$ are based on data reported in Appendix \ref{A-1}.

In general, the mean path is consistent in the three methods, but UQ is significantly different, as well as the values of $g_{t_f}$. In particular: \begin{description}
  \item[(a) Mt. St. Helens, 1982 - line length] data values are initially scattered, until $t = t_e - 20$, and then become more aligned. $\alpha \approx 2$, and $E[t_f]$ overestimates $t_e$ of $2$-$3$ days in all the Methods. Uncertainty range is $50\%$ larger in Method 2 and 3 compared to Method 1.
  \item[(b) Mt. St. Helens, 1982 - tilt] this example refers to the same eruption of example (a), but the dataset is larger. The number of initially scattered data is relatively significant. According to HT, $\alpha= 2.2\pm 0.2$, while according to LLT $\alpha= 1.5\pm 0.5$. In the first case (red), in Method 1 $E[t_f]$ overestimates $t_e$ of $6$ days, and in Method 2 and 3 it underestimates $t_e$ of only $1$ day. Uncertainty range is about $\pm 7$ days in Method 1, and about $\pm 20$ days in Methods 2 and 3. In the second case (blue), in Method 1 $E[t_f]$ misses $t_e$ of $30$ days, outside the uncertainty range. In Method 2 and 3 $E[t_f]$ overestimates $t_e$ of $20$ days, and has a relatively small uncertainty range of $\pm 5$ days which misses $t_e$. Method 3 is slightly improved, and almost captures $t_e$ in its uncertainty range.
  \item[(c) Mt. St. Helens, 1981 - fault movement] this example is characterized by $\alpha \approx 1.6$ in HT and $\alpha = 1.3\pm 0.2$ in LLT. In the first case (red), in Method 1 $E[t_f]$ underestimates $t_e$ of only $1$ day, with uncertainty range $\pm 2$ days. Methods 2 and 3 also perform well, but uncertainty ranges increase to $\pm 9$. In the second case case (blue), in Method 1 $E[t_f]$ overestimates $t_e$ of $14$ days, outside the uncertainty range. In Methods 2 and 3, $E[t_f]$ is $1$ and $3$ days before $t_e$, respectively. The uncertainty is above $\pm 20$ days.
  \item[(d) Bezymyanny, 1960 - seismic strain] data values are persistently scattered until $t = t_e - 10$, and $\alpha \approx 1.6$. However, in Method 1, $E[t_f]$ correctly estimates $t_e$, with uncertainty range of $\pm 3$ days. In Methods 2 and 3, $E[t_f]$ underestimates $t_e$ of $3$ days, and uncertainty is increased to $\pm 9$ days.
  \item[(e) Mt. Toc, 1963 - surface movement] According to HT, $\alpha \approx 2$, while according to LLT, $\alpha= 1.7\pm0.3$. In the first case (red), in Method 1 $E[t_f]$ correctly estimates $t_e$, with uncertainty range of $\pm 2$ days. Similar performances in Method 2 and 3, with uncertainty range of $\pm 4$ days. In the second case (blue), in Method 1 $E[t_f]$ overestimates $t_e$ of $5$ days, but the uncertainty range is about $\pm 10$ days and captures it. In Method 2 $E[t_f]$ overestimates $t_e$ of $4$ days and uncertainty is reduced to $\pm 4$ days. Method 3 gives very similar results to Method 1.
  \item[(f) Mt. Toc, 1960 - surface movement] this example is characterized by a very low $\alpha\approx 1.1$. Even if data are not significantly scattered, uncertainty is very high because the ODE solutions are almost asymptotical to the real axis. In Method 1, $E[t_f]$ significantly overestimates $t_e$ of more than $100$ days, and uncertainty range is at the same scale. In Method 2, $E[t_f]$ overestimates $t_e$ of $34$ days, and uncertainty range is reduced to $\pm 16$ days. In Method 3, $E[t_f]$ overestimates $t_e$ of $25$ days, and the uncertainty range is about $\pm 35$ days, capturing $t_e$.
\end{description}

In summary, when $\alpha\approx 2$ Method 1 generally provides a good estimator of $t_e$, but often only the HT method allows these robust estimates. Instead, when $\alpha \le 1.6$, Method 1 tends to overestimate $t_e$. Method 2 reduces this issue, but model uncertainty is neglected and the estimate can miss $t_e$. Method 3 enhances Method 2, and performs significantly better in this case. Its doubly stochastic nature allows the production of either mean probability values or more conservative 95$^{th}$ percentile values.

\newpage
\section{Examples of probability forecasts}
The estimators defined in the previous section are informed by the entire sequence of data, up to the eruption onset or landslide initiation $t_e$. This provides useful insight on the validity of the estimators, but it is not a forecast. Indeed in any forecasting problem the sequence of data is available up to a time $t_1<t_e$, that represents the current time of the forecast. All the data collected after time $t_1$ cannot be considered.

In the following figures we display forecasts of $t_e$ based on the ODE method, and obtained considering only the data collected in limited time windows $T=[t_2,t_1]$. We focus on the two examples of (i) Mt. St. Helens, 1982 - line length $(\alpha\approx1.98)$, and (ii) Bezymyanny, 1960 - seismic strain $(\alpha\approx1.65)$. Figure \ref{Fig13} adopts Method 1, Figure \ref{Fig8_10} Method 2 and Figure \ref{Fig9_11} Method 3. Method 1 and mean pdf in Method 3 both implement a Monte Carlo of 20,000 samples, Method 2 a Monte Carlo of 5,000 samples, the percentile values in Method 3 are based on a hierarchical Monte Carlo of more than $6e5$ samples.

Forecasting problems are significantly uncertain, because they are inherently extrapolations based on past data. In Methods 1 and 3, sometimes $P\{t_f=\infty\} >0$ and there is a non-negligible chance that the solution path never hits the real axis. In contrast, if $P\{t_f<t_1\} >0$ there is a chance that $\hat\eta(t_1)<0$ and the equation is not well defined. The probability of both these events is quantified.

In both examples we consider three time windows progressively moving towards $t_e$, including new observations and neglecting the old data. In particular, (a-b) rely on the initial scattered data, (c-d) include both scattered and aligned observations, (e-f) generally forget about scattered data. We remark that $\alpha$ remains fixed for simplicity.

In general, uncertainty is always reduced while getting closer to $t_e$. In particular:
\begin{description}
  \item[(a) Mt. St. Helens, 1982 - line length] Based on the first time window (blue) $t_e-[40,20]$, in Method 1 $E[t_f]$ overestimates $t_e$ of $90$ days, at the boundary of the uncertainty range. In Method 2 $E[t_f]$ overestimates $t_e$ of $48$ days, outside the uncertainty range. In Method 3 $E[t_f]$ overestimates $t_e$ of $57$ days, inside the uncertainty range. In Methods 1 and 3, $P\{t_f=\infty\} > 15\%$. Based on the second time window (light blue) $t_e-[40,15]$, in Method 1 $E[t_f]$ overestimates $t_e$ of $37$ days, inside the uncertainty range. In Method 2 $E[t_f]$ overestimates $t_e$ of $28$ days, again outside the uncertainty range. In Method 3 $E[t_f]$ overestimates $t_e$ of $30$ days, inside the uncertainty range. In Methods 1 and 3, $P\{t_f=\infty\} \approx 2\%$. Based on the third time window (red) $t_e-[30,10]$, in Method 1 $E[t_f]$ estimates correctly $t_e$, with an uncertainty range of about $\pm 8$ days. In Method 2 $E[t_f]$ underestimates $t_e$ of $1$ day, with an uncertainty range of about $\pm 4$ days. Method 3 performs similarly to Method 1.
  \item[(d) Bezymyanny, 1960 - seismic strain] This example is characterized by uncertainty ranges generally skewed towards higher values. Based on the first time window (blue) $t_e-[37,17]$, in Method 1 $E[t_f]$ overestimates $t_e$ of $21$ days, inside the uncertainty range. In Method 2 $E[t_f]$ overestimates $t_e$ of $1$ day. In Method 3 $E[t_f]$ overestimates $t_e$ of $5$ days, well inside the uncertainty range. In Methods 1 and 3, $P\{t_f=\infty\} \approx 9\%$. Based on the second time window (light blue) $t_e-[30,10]$, in Method 1 $E[t_f]$ overestimates $t_e$ of $3$ days, inside the uncertainty range. In Method 2 $E[t_f]$ underestimates $t_e$ of $1$ day, uncertainty $[-7,11]$ days. In Method 3 $E[t_f]$ estimates $t_e$ correctly, uncertainty of $[-8,17]$ days. Based on the third time window (violet) $t_e-[20,5]$, in Method 1 $E[t_f]$ underestimates $t_e$ of $1$ day, uncertainty of $[-3,6]$ days. In Method 2 $E[t_f]$ underestimates $t_e$ of $3$ days, uncertainty range of about $[-2,3]$ days. Method 3 performs similarly to Method 1. We remark that in Methods 1 and 3, $P\{t_f<t_1\} \approx 15\%$.
\end{description}

In summary, Method 1 and Method 3 give similar results, but the more complex UQ related to Method 3 improves its performance, particularly when uncertainty is large. Method 2 tends to give a competitive forecast only when the eruption is close, and model uncertainty is generally reduced. The doubly stochastic formulation of Method 3 appears to have a significant impact.

\begin{figure}[H]\vskip-0.5cm
\centering
\includegraphics[width=0.85\textwidth]{Fig13_new.png}
\caption{Forecasts of $t_f$ based on Method 1. In (a,c,e) and (b,d,f) two examples are tested on three different time windows $T$. The bold line is $g_{t_f}$. Thin dashed lines bound the $90\%$ confidence interval of the ODE paths, and a thin continuous line is the mean path. A dashed black line marks $t_e$.}
\label{Fig13}
\end{figure}

\begin{figure}[H]\vskip-0.5cm
\centering
\includegraphics[width=0.85\textwidth]{Fig8_9new.png}
\caption{Forecasts of $t_f$ based on Method 2. In (a,c,e) and (b,d,f) two examples are tested on three different time windows $T$. The bold line is $g_{t_f}$. Thin dashed lines bound the $90\%$ confidence interval of the SDE paths, and a thin continuous line is the mean path. Thin dotted lines show examples of random paths. A thin dashed line marks $1/x_0$, and a dashed black line marks $t_e$.}
\label{Fig8_10}
\end{figure}

\begin{figure}[H]\vskip-0.5cm
\centering
\includegraphics[width=0.85\textwidth]{Fig10_11new.png}
\caption{Forecasts of $t_f$ based on Method 3. In (a,c,e) and (b,d,f) two examples are tested on three different time windows $T$. The bold line is $g_{t_f}$, and bold dashed lines are its 5$^{th}$ and 95$^{th}$ percentile values. Thin dashed lines bound the $90\%$ confidence interval of the SDE paths, and a thin continuous line is the mean path. Thin dotted lines show examples of random paths. A thin dashed line marks $1/x_0$, and a dashed black line marks $t_e$.}
\label{Fig9_11}
\end{figure}

\section{Discussion}
We described three different methods for estimating $t_f$, the ODE-based Method 1, the new SDE-based Method 2, and its doubly stochastic formulation Method 3. We tested the methods on six case studies, and in two of them we also performed forecasts on moving time windows. Figure \ref{Fig15} summarizes the material failure likelihood in the $t_e$ day of the six case studies, reported as a probability percentage. Plot (a) compares Method 1 (black bars) and Method 2 (colored bars). Method 1 always outperforms Method 2 when $\alpha$ is based on the more accurate HT (red bars), and provides likelihoods above $15\%$ in four cases over five. In contrast, when $\alpha$ is based on LLT (blue bars) the two methods provide similar likelihoods, below $5\%$ in four cases over five, and below $1\%$ in two cases. Plot (b) displays the likelihood provided by the doubly stochastic Method 3. Full colored bars report the mean likelihood, shaded bars the 95$^{th}$ percentiles of the likelihood. Mean likelihoods are very similar to those provided by Method 2, but when those were below $1\%$, these are $\approx 1\%$. The 95$^{th}$ percentile values are significantly higher. In particular, when $\alpha$ is based on LLT (blue bars), Method 3 percentiles are all higher than the Method 1 values.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{Fig15_plus.png}
\caption{Barplots of the likelihood $P\{t_e=t_f\}$. In plot (a) the black bars assume Method 1, the colored bars Method 2. Plot (b) assumes Method 3, and the full bars are the mean values, and the shaded bars are the 95$^{th}$ percentile values of the likelihood.}
\label{Fig15}
\end{figure}

This features are confirmed by the material failure likelihoods in the forecasting examples based on the moving window. Figure \ref{Fig16} summarizes these likelihoods. Plot (a) compares Method 1 (black bars) and Method 2 (colored bars). In Mt. St. Helens, 1982 - line length (blue), Method 2 outperforms Method 1 only in the third time window, and it is the only likelihood above $10\%$. In Bezymyanny, 1960 - seismic strain (red), Method 2 outperforms Method 1 only in the first time window, and the likelihoods are all close to $5\%$. Plot (b) displays the likelihoods provided by the doubly stochastic Method 3. Full colored bars report the mean likelihood, shaded bars its 95$^{th}$ percentile values. In this case, mean likelihoods are very similar to those provided by Method 1, but slightly lower. The 95$^{th}$ percentile values are again significantly higher, around $5\%$ in the first and second time windows, and about $16\%$ and $12\%$ in the Mt. St. Helens and Bezyamyanny case studies, respectively.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{Fig16_plus.png}
\caption{Barplots of the likelihood $P\{t_e=t_f\}$ in two forecasting examples, on three different time windows. In plot (a) the black bars assume Method 1, the colored bars Method 2. Plot (b) assumes Method 3, and the full bars are the mean values, and the shaded bars are the 95$^{th}$ percentile values of the likelihood.}
\label{Fig16}
\end{figure}

\section{Conclusions}
In this study, we have introduced a new doubly stochastic method for performing material failure forecasts. The method enhances the well known FFM equation, introducing a new formulation similar to the Hull-White model. The model is a mean-reverting SDE, which assumes the traditional ODE as the mean solution. New parameters include the noise standard deviation $\sigma$ and the mean-reversion rapidity $\gamma$. They are estimated based on the properties of the residuals in the original linearized problem. The implementation allows the model to make excursions from the classical solutions, including the possibility of some degree of aleatory uncertainty in the estimation. This provides probability forecasts instead that deterministic predictions.

We compared the new method and the forecasting method based on the classical formulation. We also compared an Hull-White model without considering the model uncertainty, and its doubly stochastic formulation. A comparison is performed on six historical datasets of precursory signals already studied with the classical FFM, including tilt, line-length, and fault movement at Mt. St. Helens, 1981-82, seismic signals registered from Bezymyanny, 1960, and surface movement of Mt. Toc, 1960-63. We also considered forecasting problems over moving time windows, based on data in the case studies of Mt. St. Helens, 1982 and Bezymyanny, 1960. The data shows the performance of the methods across a wide range of possible values of convexity $\alpha$ and amounts of scattering in the observations, and the increased forecasting skill of the doubly stochastic formulation in Method 3.

The doubly stochastic formulation is particularly impacting in the forecasts because it enables the calculation of the 95$^{th}$ percentiles of the probability of failure. This values are generally higher than the mean estimates, and represent the \emph{worst case scenario} with a probability of occurrence above $5\%$. This was not possible in the classical formulation. This approach is the subject of ongoing and future work, with the purpose to further enhance the short-term eruption forecasting robustness.

\section*{Acknowledgements}

We would like to thank Prof B. Voight for helpful discussions and inspiration. We would also like to acknowledge the support of NSF awards XXXX and YYYY.


\appendix
\section{Classical statistical analysis of FFM}\label{A-1}
In the ODE problem, regressive models can be applied on different formulations of the differential equation. Even if these formulations are algebraically equivalent, the result of the regression can change significantly. We describe three different methods reported in \cite{Voight1988}, and then fully detailed in \cite{Cornelius1995}. We follow the notation of \cite{Cornelius1995}. Nonlinear regression methods have also been developed, but in this study we relied on the linearized method for simplicity \citep{Bell2011}.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{Fig4_plus.png}
\vskip-0.5cm\caption{Methods LLT and HT applied to (a,b) St. Helens and (c,d) Bezymyanny\&Mt. Toc datasets. Different colors correspond to different data. Dashed lines bound the $90\%$ confidence interval of the regression line. Figure modified from \cite{Voight1988}.}
\label{Fig4}
\end{figure}

\paragraph{Log-rate versus log-acceleration technique (LLT)}
The application of a linear regressive model (LRM) on the equation (from eq. \ref{eq1}):
$$\log\left(\frac{dX}{dt}\right)=\alpha\log(X)+\log(A)$$
can produce estimates of $\alpha$ and $\log(A)$. It requires an approximation to the rate change, which typically suffers of data scattering. Then, $A$ is not robustly constrained by its logarithm. Moreover, the equation may be not well-posed in case of negative rates, requiring to neglect some values, or to apply the equation to $X+c > 0$.

\paragraph{Hindsight technique (HT)}
A LRM can be applied to the equation (from eq. \ref{eq2b}, with $t_0=t_f$):
$$\log(X(t))=\frac{1}{1-\alpha}\log(t_f-t)+\frac{\log[A(\alpha-1)]}{1-\alpha},$$
producing estimates of $\frac{1}{1-\alpha}$ and $\frac{\log[A(\alpha-1)]}{1-\alpha}$. It does not rely on the rate change, but requires to know the failure time $t_f$ in advance. This is the reason of its name. Thus, it is not a method producing forecasts, but can be solely used in hindcasting problems. Moreover, while the value of $\alpha$ is well constrained, the value of $A$ is not. The uncertainty range affecting $A$ is increased by the uncertainty affecting $\alpha$, and the estimate is done in logarithmic scale.

\paragraph{Linearized least-squares method (LLSM)}
Finally, a LRM can be applied to eq. \ref{eq2a}:
$$X(t)^{1-\alpha}=(1-\alpha)A(t-t_0)+\eta(t_0),$$
producing estimates of $(1-\alpha)A$ and $\hat\eta(t_0)$. It does not rely on the rate change or on the failure time, but requires an estimate of $\alpha$ from another method, or an iterative approximation possibly based on nonlinear regression.

Figure \ref{Fig4} shows the results of the LLT and HT applied to the Mt. St. Helens (a,b), and to the Bezyamyanny \& Mt. Toc datasets (c,d). We note that the accuracy of HT is generally higher. In detail, the Mt. St. Helens tilt dataset shows significantly discordant results between LLT and HT. This is motivated by the great scattering in the initial measurements, and discarding the first ten points increases accuracy. The uncertainty affecting $\alpha$ in the Bezymyanny dataset according to LLT is very large and only HT is implemented in our examples. The HT results of the Mt. Toc, 1960 dataset were not provided in the original study.
\newpage
\section{Sensitivity analysis on the noise properties}\label{A-2}
Discrete observations provide us information on $K=\frac{\sigma^2}{\gamma}$, which is the variance of the solution of the Ornstein-Uhlenbeck process associated to our SDE. However, solutions with the same $K$ can look significantly different, as shown in Figure \ref{Fig3}b.

The estimators in all our case studies assume $\gamma=1/15$.  This is a choice based on the empirical observation that the total length of temporal sequence is at the scale of $45$ days, and the duration of well-aligned observations is at the scale of $15$ days. In Figure \ref{Fig12} we show examples of solutions with doubled or halved $\gamma$. There is an apparent effect on the $90\%$ confidence interval of the SDE paths, which is enlarged increasing $\gamma$, and terminally bent down towards the real axis. However, the effect of $g_{t_f}$ is minor, and increasing $\gamma$ of four times reduces $E[t_f]$ of about $5$ days.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{Fig12_plus.png}
\caption{Forecasts of $t_f$ based on Method 2. The solutions assume equal $K=\frac{\sigma^2}{\gamma}$, but different $(\sigma, \gamma)$. In plots (a,c) $\gamma^{-1}=7.5$, and in plots (b,d) $\gamma^{-1}=30$. The bold line is the pdf of $t_f$. Thin dashed lines bound the $90\%$ confidence interval of the SDE paths, and a thin continuous line is the median path. Thin dotted lines show examples of random paths. A thin dashed line marks $1/x_0$, and a dashed black line marks $t_e$.}
\label{Fig12}
\end{figure}
\bibliographystyle{apalike}
\bibliography{bibfileFFM}
\end{document}



